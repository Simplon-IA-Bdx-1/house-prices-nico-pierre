{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Regression on House Prices (1D) with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In this notebook we show how to perform linear regression on house prices data, using Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Define `X_train` and `Y_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import transpose\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib notebook\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(42)\n",
    "# tf.random.set_seed(42)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('sources/train.csv')\n",
    "\n",
    "X_train_ID = data['Id']\n",
    "\n",
    "data.fillna(0)\n",
    "data['Surface'] = data['GrLivArea'] + data['TotalBsmtSF']\n",
    "\n",
    "Y_train = data.SalePrice.values.astype(float)\n",
    "X_train = transpose([data.Surface.values.astype(float)])\n",
    "print(f\"X train {X_train.shape}\")\n",
    "print(f\"Y train {Y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dataviz X_train Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sns.regplot(x = X_train, y = Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Sequential avec Keras\n",
    "Define input layer. Number of neurons = number of features in `x`.\n",
    "\n",
    "Define output layer, with 1 neuron.\n",
    "`Dense` creates _fully-connected_ layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = Sequential()\n",
    "model = Sequential([\n",
    "    Input(shape=X_train.shape[1:]),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scale features\n",
    "\n",
    "\"Normalizing\" the data should help prevent values from \"exploding\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Set up optimizer and \"compile\" model\n",
    "In Keras, optimizer is specified when \"compiling\" model.\n",
    "(Last step to fix model training code!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "loss=\"mse\"\n",
    "LEARNING_RATE = 0.001\n",
    "model.compile(loss=loss, optimizer=SGD(lr=LEARNING_RATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fit model (i.e. run optimization)\n",
    "\n",
    "The model still hasn't \"seen\" any data yet...\n",
    "\n",
    "* With SGD we can choose the amount of data to be used to compute the loss function (`BATCH_SIZE`). This can be useful when the whole dataset doesn't fit in memory. We'll revisit this later!\n",
    "* We need to choose for how many iterations to run SGD (`EPOCHS`).\n",
    "* The `fit` method is a loop over epochs and batches!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = X_train.shape[0] # computing the loss over the whole dataset\n",
    "EPOCHS = 2000 # how many iterations over the whole dataset\n",
    "history = model.fit(X_train, Y_train, epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.relplot(x=hist.index, y=\"loss\", kind=\"line\", data=hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualize model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Model is line defined by coefficient `W` and bias (a.k.a. intercept) `b`\n",
    "* Just need to plot 2 points and link them... \n",
    "    * x-axis: let's choose minimum and maximum of `X_train`\n",
    "    * y-axis: given by model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x_line = np.transpose([[X_train.min(), X_train.max()]])\n",
    "y_line = model.predict(x_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Point 1: [\" + str(x_line[0][0]) + \", \" + str(y_line[0]) + \" ]\")\n",
    "print(\"Point 2: [\" + str(x_line[1][0]) + \", \" + str(y_line[1]) + \" ]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(X_train, Y_train, \"b.\")\n",
    "plt.plot(x_line, y_line, \"r-\") # \"r-\" means we plot data points in red and link them with a line\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('sources/test.csv')\n",
    "data_test.fillna(0, inplace=True)\n",
    "data_test['Surface'] = data_test['TotalBsmtSF'] + data_test['GrLivArea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = transpose([data_test.Surface.values.astype(float)])\n",
    "print(f\"X test {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test) # On applique le scaler sur les Surfaces du dataset de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = model.predict(x=X_test)\n",
    "Y_test = np.reshape(Y_test, Y_test.shape[0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[660:662]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = data_test['Surface'], y = Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['SalePrice'] = Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.drop(data_test.columns.difference(['Id','SalePrice']), 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.to_csv('storage/kaggle_submission_file.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "ml-workshops"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "livereveal": {
   "scroll": true
  },
  "nteract": {
   "version": "0.15.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.6956481933594px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
