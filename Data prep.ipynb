{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep\n",
    "\n",
    "Based on [a Notebook from kaggle](https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./sources/train.csv')\n",
    "df_test = pd.read_csv('./sources/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data viz\n",
    "\n",
    "### Check columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive statistics summary\n",
    "\n",
    "df_train['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram\n",
    "\n",
    "sns.distplot(df_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relations between SalePrice and most interesting Numerical features (TotalBsmtSF & GrLivArea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Against GrLivArea\n",
    "\n",
    "sns.scatterplot(x=df_train['GrLivArea'], y=df_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see at least two outlayers with a high GrLivArea for a low SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Against TotalBsmtSF\n",
    "\n",
    "sns.scatterplot(x=df_train['TotalBsmtSF'], y=df_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see at least one outlaer with a great TotalBsmtSF and a low SalePrice. <br />\n",
    "Also that a 0 TotalBsmtSF can have SalePrice\n",
    "\n",
    "#### Relation between SalePrice and most interesting Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Against OverallQual\n",
    "\n",
    "sns.boxplot(x='OverallQual', y='SalePrice', data=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Against YearBuilt\n",
    "\n",
    "sns.boxplot(x='YearBuilt', y='SalePrice', data=df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The others..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix\n",
    "\n",
    "cormat = df_train.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(cormat, vmax=.8, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saleprice correlation matrix\n",
    "\n",
    "k = 10  # number of variables for heatmap\n",
    "cols = cormat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
    "cm = np.corrcoef(df_train[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={\n",
    "                 'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GarageCar & GarageArea and TotalBsmtSF & 1stFlrSF are strongly correlated two by two so we may want to keep just one feature of each couple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatterplot\n",
    "\n",
    "sns.set()\n",
    "cols = ['SalePrice', 'OverallQual', 'GrLivArea',\n",
    "        'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n",
    "sns.pairplot(df_train[cols], height=2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df_train.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df_train.isnull().sum()/df_train.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dealing with missing data\n",
    "\n",
    "# Taking off the too many missing datas columns\n",
    "df_train = df_train.drop((missing_data[missing_data['Total'] > 1]).index, 1)\n",
    "\n",
    "# Taking off the one row missing data in Electrical\n",
    "df_train = df_train.drop(df_train.loc[df_train['Electrical'].isnull()].index)\n",
    "\n",
    "# just checking that there's no missing data missing...\n",
    "df_train.isnull().sum().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same job and the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking off the same columns as we did for the train set\n",
    "df_test = df_test.drop((missing_data[missing_data['Total'] > 1]).index, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing data\n",
    "\n",
    "saleprice_scaled = StandardScaler().fit_transform(\n",
    "    df_train['SalePrice'][:, np.newaxis])\n",
    "low_range = saleprice_scaled[saleprice_scaled[:, 0].argsort()][:10]\n",
    "high_range = saleprice_scaled[saleprice_scaled[:, 0].argsort()][-10:]\n",
    "print('outer range (low) of the distribution:')\n",
    "print(low_range)\n",
    "print('\\nouter range (high) of the distribution:')\n",
    "print(high_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check again the scatterplots to look for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=df_train['GrLivArea'], y=df_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two points with high GrLivArea seems to be outliers however, the two highest points of SalePrice seems to be \"in the line\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting points\n",
    "df_train.sort_values(by='GrLivArea', ascending=False)[:2]\n",
    "df_train = df_train.drop(df_train[df_train['Id'] == 1299].index)\n",
    "df_train = df_train.drop(df_train[df_train['Id'] == 524].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normality exploration\n",
    "\n",
    "#### SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram and normal probability plot\n",
    "sns.distplot(df_train['SalePrice'], fit=norm)\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df_train['SalePrice'], plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `'SalePrice'` as a \"big tail\". We can avoid this by applying a `log` to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying log transformation\n",
    "df_train['SalePrice'] = np.log(df_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed histogram and normal probability plot\n",
    "sns.distplot(df_train['SalePrice'], fit=norm)\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df_train['SalePrice'], plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That fits much better to a normal distribution\n",
    "\n",
    "#### GrLivArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram and normal probability plot\n",
    "sns.distplot(df_train['GrLivArea'], fit=norm)\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df_train['GrLivArea'], plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same desease, same medecine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data transformation\n",
    "df_train['GrLivArea'] = np.log(df_train['GrLivArea'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['GrLivArea'] = np.log(df_test['GrLivArea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed histogram and normal probability plot\n",
    "sns.distplot(df_train['GrLivArea'], fit=norm)\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df_train['GrLivArea'], plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TotalBsmtSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram and normal probability plot\n",
    "sns.distplot(df_train['TotalBsmtSF'], fit=norm)\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df_train['TotalBsmtSF'], plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the 0 presents in the dataset, we cannot use `log`. <br />\n",
    "So we create a new binary feature that says if there's a basement or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column for new variable (one is enough because it's a binary categorical feature)\n",
    "# if area>0 it gets 1, for area==0 it gets 0\n",
    "df_train['HasBsmt'] = pd.Series(\n",
    "    len(df_train['TotalBsmtSF']), index=df_train.index)\n",
    "df_train['HasBsmt'] = 0\n",
    "df_train.loc[df_train['TotalBsmtSF'] > 0, 'HasBsmt'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data\n",
    "df_train.loc[df_train['HasBsmt'] == 1,\n",
    "             'TotalBsmtSF'] = np.log(df_train['TotalBsmtSF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram and normal probability plot\n",
    "sns.distplot(df_train[df_train['TotalBsmtSF'] > 0]['TotalBsmtSF'], fit=norm)\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(\n",
    "    df_train[df_train['TotalBsmtSF'] > 0]['TotalBsmtSF'], plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same on test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column for new variable (one is enough because it's a binary categorical feature)\n",
    "# if area>0 it gets 1, for area==0 it gets 0\n",
    "df_test['HasBsmt'] = pd.Series(\n",
    "    len(df_test['TotalBsmtSF']), index=df_test.index)\n",
    "df_test['HasBsmt'] = 0\n",
    "df_test.loc[df_test['TotalBsmtSF'] > 0, 'HasBsmt'] = 1\n",
    "\n",
    "# transform data\n",
    "df_test.loc[df_test['HasBsmt'] == 1,\n",
    "             'TotalBsmtSF'] = np.log(df_test['TotalBsmtSF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### homoscedasticity\n",
    "\n",
    "#### 'SalePrice' and 'GrLivArea'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "plt.scatter(df_train['GrLivArea'], df_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'SalePrice' with 'TotalBsmtSF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "plt.scatter(df_train[df_train['TotalBsmtSF'] > 0]['TotalBsmtSF'],\n",
    "            df_train[df_train['TotalBsmtSF'] > 0]['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy datas for categorical features\n",
    "\n",
    "To be shure to have the same number of columns on both train and test sets, we concatenate them before using the `get_dummies` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['train'] = 1\n",
    "df_test['train'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([df_train, df_test], axis=0, sort=False)\n",
    "\n",
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the dummy features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical variable into dummy\n",
    "combined = pd.get_dummies(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split again in to separates datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = combined[combined['train'] == 1]\n",
    "df_test = combined[combined['train'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(['train'], axis=1, inplace=True)\n",
    "df_test.drop(['train'], axis=1, inplace=True)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill Na in the train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And drop the 'SalePrice' column that got into the test set while combining the two sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(['SalePrice'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export cleaned files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('./sources/clean_train.csv')\n",
    "df_test.to_csv('./sources/clean_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "211.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
