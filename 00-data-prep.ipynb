{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep\n",
    "\n",
    "Based on [a Notebook from kaggle](https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./sources/train.csv')\n",
    "df_test = pd.read_csv('./sources/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data viz\n",
    "\n",
    "### Check columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All columns\n",
    "print(df_train.columns)\n",
    "\n",
    "# Numerical values\n",
    "num_col = df_train.select_dtypes(exclude=['object']).columns\n",
    "print(num_col)\n",
    "\n",
    "# Categorical values\n",
    "cat_col = df_train.select_dtypes(include=['object']).columns\n",
    "print(cat_col)\n",
    "\n",
    "all_col = {\n",
    "    'num_col': num_col,\n",
    "    'cat_col': cat_col\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pickle to save the numerical and categorical columns\n",
    "with open('./columns.pkl', 'wb') as col:\n",
    "    pickle.dump(all_col, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive statistics summary\n",
    "\n",
    "df_train['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram\n",
    "\n",
    "sns.distplot(df_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relations between SalePrice and most interesting Numerical features (TotalBsmtSF & GrLivArea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Against GrLivArea\n",
    "\n",
    "sns.scatterplot(x=df_train['GrLivArea'], y=df_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see at least two outlayers with a high GrLivArea for a low SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Against TotalBsmtSF\n",
    "\n",
    "sns.scatterplot(x=df_train['TotalBsmtSF'], y=df_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see at least one outlaer with a great TotalBsmtSF and a low SalePrice. <br />\n",
    "Also that a 0 TotalBsmtSF can have SalePrice\n",
    "\n",
    "#### Relation between SalePrice and most interesting Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Against OverallQual\n",
    "\n",
    "sns.boxplot(x='OverallQual', y='SalePrice', data=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Against YearBuilt\n",
    "\n",
    "sns.boxplot(x='YearBuilt', y='SalePrice', data=df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The others..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix\n",
    "\n",
    "cormat = df_train.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(cormat, vmax=.8, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saleprice correlation matrix\n",
    "\n",
    "k = 10  # number of variables for heatmap\n",
    "cols = cormat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
    "cm = np.corrcoef(df_train[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={\n",
    "                 'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GarageCar & GarageArea and TotalBsmtSF & 1stFlrSF are strongly correlated two by two so we may want to keep just one feature of each couple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatterplot\n",
    "\n",
    "sns.set()\n",
    "cols = ['SalePrice', 'OverallQual', 'GrLivArea',\n",
    "        'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n",
    "sns.pairplot(df_train[cols], height=2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df_train.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df_train.isnull().sum()/df_train.isnull().count()\n",
    "           ).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dealing with missing data\n",
    "\n",
    "# Taking off the too many missing datas columns\n",
    "df_train = df_train.drop((missing_data[missing_data['Total'] > 1]).index, 1)\n",
    "\n",
    "# Taking off the one row missing data in Electrical\n",
    "df_train = df_train.drop(df_train.loc[df_train['Electrical'].isnull()].index)\n",
    "\n",
    "# just checking that there's no missing data missing...\n",
    "df_train.isnull().sum().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same job and the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking off the same columns as we did for the train set\n",
    "df_test = df_test.drop((missing_data[missing_data['Total'] > 1]).index, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing data\n",
    "\n",
    "saleprice_scaled = StandardScaler().fit_transform(\n",
    "    df_train['SalePrice'][:, np.newaxis])\n",
    "low_range = saleprice_scaled[saleprice_scaled[:, 0].argsort()][:10]\n",
    "high_range = saleprice_scaled[saleprice_scaled[:, 0].argsort()][-10:]\n",
    "print('outer range (low) of the distribution:')\n",
    "print(low_range)\n",
    "print('\\nouter range (high) of the distribution:')\n",
    "print(high_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check again the scatterplots to look for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=df_train['GrLivArea'], y=df_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two points with high GrLivArea seems to be outliers however, the two highest points of SalePrice seems to be \"in the line\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting points\n",
    "df_train.sort_values(by='GrLivArea', ascending=False)[:2]\n",
    "df_train = df_train.drop(df_train[df_train['Id'] == 1299].index)\n",
    "df_train = df_train.drop(df_train[df_train['Id'] == 524].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normality exploration\n",
    "\n",
    "#### SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram and normal probability plot\n",
    "sns.distplot(df_train['SalePrice'], fit=norm)\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df_train['SalePrice'], plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `'SalePrice'` as a \"big tail\". We can avoid this by applying a `log` to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying log transformation\n",
    "df_train['SalePrice'] = np.log(df_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed histogram and normal probability plot\n",
    "sns.distplot(df_train['SalePrice'], fit=norm)\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df_train['SalePrice'], plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That fits much better to a normal distribution\n",
    "\n",
    "#### GrLivArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram and normal probability plot\n",
    "sns.distplot(df_train['GrLivArea'], fit=norm)\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df_train['GrLivArea'], plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same desease, same medecine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data transformation\n",
    "df_train['GrLivArea'] = np.log(df_train['GrLivArea'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['GrLivArea'] = np.log(df_test['GrLivArea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed histogram and normal probability plot\n",
    "sns.distplot(df_train['GrLivArea'], fit=norm)\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df_train['GrLivArea'], plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TotalBsmtSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram and normal probability plot\n",
    "sns.distplot(df_train['TotalBsmtSF'], fit=norm)\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df_train['TotalBsmtSF'], plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the 0 presents in the dataset, we cannot use `log`. <br />\n",
    "So we create a new binary feature that says if there's a basement or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column for new variable (one is enough because it's a binary categorical feature)\n",
    "# if area>0 it gets 1, for area==0 it gets 0\n",
    "df_train['HasBsmt'] = pd.Series(\n",
    "    len(df_train['TotalBsmtSF']), index=df_train.index)\n",
    "df_train['HasBsmt'] = 0\n",
    "df_train.loc[df_train['TotalBsmtSF'] > 0, 'HasBsmt'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data\n",
    "df_train.loc[df_train['HasBsmt'] == 1,\n",
    "             'TotalBsmtSF'] = np.log(df_train['TotalBsmtSF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram and normal probability plot\n",
    "sns.distplot(df_train[df_train['TotalBsmtSF'] > 0]['TotalBsmtSF'], fit=norm)\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(\n",
    "    df_train[df_train['TotalBsmtSF'] > 0]['TotalBsmtSF'], plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same on test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column for new variable (one is enough because it's a binary categorical feature)\n",
    "# if area>0 it gets 1, for area==0 it gets 0\n",
    "df_test['HasBsmt'] = pd.Series(\n",
    "    len(df_test['TotalBsmtSF']), index=df_test.index)\n",
    "df_test['HasBsmt'] = 0\n",
    "df_test.loc[df_test['TotalBsmtSF'] > 0, 'HasBsmt'] = 1\n",
    "\n",
    "# transform data\n",
    "df_test.loc[df_test['HasBsmt'] == 1,\n",
    "             'TotalBsmtSF'] = np.log(df_test['TotalBsmtSF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### homoscedasticity\n",
    "\n",
    "#### 'SalePrice' and 'GrLivArea'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "plt.scatter(df_train['GrLivArea'], df_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'SalePrice' with 'TotalBsmtSF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "plt.scatter(df_train[df_train['TotalBsmtSF'] > 0]['TotalBsmtSF'],\n",
    "            df_train[df_train['TotalBsmtSF'] > 0]['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy datas for categorical features\n",
    "\n",
    "To be shure to have the same number of columns on both train and test sets, we concatenate them before using the `get_dummies` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['train'] = 1\n",
    "df_test['train'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([df_train, df_test], axis=0, sort=False)\n",
    "\n",
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the dummy features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical variable into dummy\n",
    "combined = pd.get_dummies(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split again in to separates datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = combined[combined['train'] == 1]\n",
    "df_test = combined[combined['train'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(['train'], axis=1, inplace=True)\n",
    "df_test.drop(['train'], axis=1, inplace=True)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill Na in the train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And drop the 'SalePrice' column that got into the test set while combining the two sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(['SalePrice'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export cleaned files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('./sources/clean_train.csv', index=False)\n",
    "df_test.to_csv('./sources/clean_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "211.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
