{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Regression on House Prices (1D) with Keras\n",
    "\n",
    "All Rights Reserved © <a href=\"http://www.louisdorard.com\">Louis Dorard</a>\n",
    "\n",
    "<img src=\"http://s3.louisdorard.com.s3.amazonaws.com/DL_icon.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In this notebook we show how to perform linear regression on house prices data, using Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Define `X_train` and `y_train`\n",
    "\n",
    "Run [House Prices 1D](House-Prices-1D.ipynb) notebook to create `data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run House-Prices-1D.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Output is `SalePrice`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_train = data.SalePrice.values.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Use `Surface` as our only feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import transpose\n",
    "X_train = transpose([data.Surface.values.astype(float)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualize data in 2D\n",
    "\n",
    "Initialize plotting lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Plot data as yellow dots (achieved with `\"y.\"` option):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_train, y_train, \"y.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The idea here is to find a line that \"fits\" the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## About Keras\n",
    "\n",
    "* High-level API: describe NN structure in simple and convenient way\n",
    "* Exists in TensorFlow, and outside (can use other libraries such as MXNet as numerical backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model relationship between `x` and  `y`\n",
    "\n",
    "We're looking for `W` and `b` such that <!-- .element: class=\"fragment\" -->\n",
    "\n",
    "`x * W + b` is a good approximation of `y` <!-- .element: class=\"fragment\" -->\n",
    "\n",
    "for all `(x, y)` input-output pairs in training. <!-- .element: class=\"fragment\" -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Main model type in Keras is sequence of \"layers\", called `Sequential`. In our case:\n",
    "\n",
    "* 1 input layer (for `x`)\n",
    "* 1 output layer (for `y`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Define input layer. Number of neurons = number of features in `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "model.add(Input(shape=X_train.shape[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Define output layer, with 1 neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`Dense` creates _fully-connected_ layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Alternative network creation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=X_train.shape[1:]),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choose \"loss\" to minimize\n",
    "\n",
    "* Error = difference between prediction `x * W + b` and true output `y`\n",
    "* Compute Mean Squared Error over whole dataset\n",
    "* MSE is a \"loss function\"; the smaller, the better\n",
    "* Loss value depends on `W`, `b`, and dataset\n",
    "    * => We want values of `W` and `b` that minimize loss on given training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 'mse'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Set up optimizer and \"compile\" model\n",
    "\n",
    "Idea: iterative way to find lowest point of mountain, blindfolded?\n",
    "\n",
    "* “What is the direction of steepest descent under my feet?” => _gradient_\n",
    "* Follow gradient by a certain step size, called _learning step_ (or _learning rate_ ).\n",
    "    \n",
    "This is called _(Stochastic) Gradient Descent_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Gradient Descent - Aurélien Géron](figures/GD-Geron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(See Figure 4-3 in _Hands-on ML_ book by Aurélien Géron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In Keras, optimizer is specified when \"compiling\" model.\n",
    "\n",
    "(Last step to fix model training code!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "LEARNING_RATE = 0.001\n",
    "model.compile(loss=loss, optimizer=SGD(lr=LEARNING_RATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Remarks:\n",
    "\n",
    "* Procedure starts from random value => need to consider random number generator seed!\n",
    "* Figure is in 1D, but 2 Dimensions when going down a mountain...\n",
    "* Our linear regression problem is in 2D, because 2 parameters to learn (`W` and `b`)\n",
    "* Benefits of \"compiling\" to be discussed in future notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fit model (i.e. run optimization)\n",
    "\n",
    "The model still hasn't \"seen\" any data yet...\n",
    "\n",
    "* With SGD we can choose the amount of data to be used to compute the loss function (`BATCH_SIZE`). This can be useful when the whole dataset doesn't fit in memory. We'll revisit this later!\n",
    "* We need to choose for how many iterations to run SGD (`EPOCHS`).\n",
    "* The `fit` method is a loop over epochs and batches!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = X_train.shape[0] # computing the loss over the whole dataset\n",
    "EPOCHS = 100 # how many iterations over the whole dataset\n",
    "history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scale features\n",
    "\n",
    "\"Normalizing\" the data should help prevent values from \"exploding\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Plot data again](#Visualize-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reset model\n",
    "\n",
    "Simplest way to reset all weights & biases is to re-execute the definition of `model`.\n",
    "\n",
    "We can then fit again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "#plt.gca().set_ylim(0, 1)\n",
    "plt.title('Model performance throughout training')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualize model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Model is line defined by coefficient `W` and bias (a.k.a. intercept) `b`\n",
    "* Just need to plot 2 points and link them... \n",
    "    * x-axis: let's choose minimum and maximum of `X_train`\n",
    "    * y-axis: given by model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_line = np.transpose([[X_train.min(), X_train.max()]])\n",
    "y_line = model.predict(x_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Point 1: [\" + str(x_line[0][0]) + \", \" + str(y_line[0]) + \" ]\")\n",
    "print(\"Point 2: [\" + str(x_line[1][0]) + \", \" + str(y_line[1]) + \" ]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(X_train, y_train, \"b.\")\n",
    "plt.plot(x_line, y_line, \"r-\") # \"r-\" means we plot data points in red and link them with a line\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Might want to increase learning rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Change learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Learning rate too small\n",
    "\n",
    "The loss decrease is too slow\n",
    "\n",
    "![Gradient Descent with a small learning step - Aurélien Géron](figures/GD-small-learning-rate-Geron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(See Figure 4-4 in _Hands-on ML_ book by Aurélien Géron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Learning rate too big\n",
    "\n",
    "Depending on the initialization, it could converge slowly, or it could diverge \n",
    "\n",
    "![Gradient Descent with a big learning step - Aurélien Géron](figures/GD-big-learning-rate-Geron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "(See Figure 4-5 in _Hands-on ML_ book by Aurélien Géron)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "ml-workshops"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "livereveal": {
   "scroll": true
  },
  "nteract": {
   "version": "0.15.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.6956481933594px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
